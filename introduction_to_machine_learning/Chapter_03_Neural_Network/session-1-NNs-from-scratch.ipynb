{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import trange\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Neural Network Training Step\n",
    "1. **Forward Pass**\n",
    "* **Input data** $X$ is fed into the network.\n",
    "* Data flows through each **layer**, which usually consists of:\n",
    "\n",
    "  * **Linear/weight layers**: compute $Z = XW + b$\n",
    "  * **Activation layers**: apply non-linear function $A = f(Z)$ (like ReLU, Softmax)\n",
    "* Final layer produces output $\\hat{y}$ (e.g., class probabilities).\n",
    "* Compute the **loss** $L(\\hat{y}, y)$ comparing output to true labels $y$.\n",
    "\n",
    "2. **Backward Pass (Backpropagation)**\n",
    "Goal: calculate gradients of loss w\\.r.t. **all parameters** (weights and biases), so you can update them with gradient descent.\n",
    "\n",
    "2.1. **Compute gradient of loss w\\.r.t. output layer output**\n",
    "\n",
    "* Using loss function derivative, e.g., for cross-entropy loss combined with softmax:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{y}} = \\hat{y} - y\n",
    "$$\n",
    "\n",
    "2.2. **Backprop through output activation (if separate)**\n",
    "\n",
    "* If softmax is separate, calculate gradient of loss w\\.r.t. softmax input $Z$ using Jacobian or simplified form above.\n",
    "* If softmax + cross-entropy are combined, this step is usually optimized.\n",
    "\n",
    "Step 2.3: Backprop through each layer **in reverse order**\n",
    "\n",
    "For each layer going backward:\n",
    "\n",
    "* **Activation layers (like ReLU):**\n",
    "\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial Z} = \\frac{\\partial L}{\\partial A} \\odot f'(Z)\n",
    "  $$\n",
    "\n",
    "  * Multiply upstream gradient by derivative of activation (element-wise).\n",
    "\n",
    "* **Weight layers (like Dense/Fully connected):**\n",
    "\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial W} = X^T \\cdot \\frac{\\partial L}{\\partial Z}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial b} = \\sum \\frac{\\partial L}{\\partial Z}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial Z} \\cdot W^T\n",
    "  $$\n",
    "\n",
    "  * Calculate gradient w\\.r.t weights and biases.\n",
    "  * Calculate gradient w\\.r.t input to pass to the previous layer.\n",
    "\n",
    "3. **Update weights**\n",
    "\n",
    "* Use gradients to update weights with gradient descent or a variant, e.g.,\n",
    "\n",
    "$$\n",
    "W := W - \\eta \\frac{\\partial L}{\\partial W}\n",
    "$$\n",
    "\n",
    "where $\\eta$ is the learning rate.\n",
    "---\n",
    "Full Example: Simple 2-layer network (Dense + ReLU + Dense + Softmax)\n",
    "\n",
    "* Forward pass:\n",
    "\n",
    "  ```\n",
    "  X -> Dense1 -> Z1\n",
    "  Z1 -> ReLU -> A1\n",
    "  A1 -> Dense2 -> Z2\n",
    "  Z2 -> Softmax -> output probabilities\n",
    "  ```\n",
    "\n",
    "* Backward pass:\n",
    "\n",
    "  ```\n",
    "  dL/dOutput = (output - true_labels)  # for softmax + cross-entropy\n",
    "  dL/dZ2 = dL/dOutput\n",
    "  dL/dA1 = Dense2.backward(dL/dZ2)\n",
    "  dL/dZ1 = ReLU.backward(dL/dA1)\n",
    "  dL/dX = Dense1.backward(dL/dZ1)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Neural Network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.inp  = None \n",
    "        self.out = None\n",
    "\n",
    "    def __call__(self, inp: np.ndarray) -> np.ndarray:\n",
    "        return self.forward(inp)\n",
    "    \n",
    "    def forward(self, inp: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def backward(self, up_graad: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def step(self, learning_rate: float) -> None:\n",
    "        pass        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Layers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization**\n",
    "- `self.w`: Represents the weight matrix of shape `(in_dim, out_dim)`, initialized using small random values.\n",
    "- `self.b`: Bias vector of shape `(1, out_dim)`, initialized to zeros.\n",
    "- `self.dw` and `self.db`: These store the computed gradients of weights and biases during backpropagation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Forward Pass**\n",
    "- The forward pass computes:\n",
    "$$\\mathbf{out} = \\mathbf{inp} \\cdot \\mathbf{W} + \\mathbf{b}$$\n",
    "where:\n",
    "  - `inp`: inp matrix of shape `(batch_size, in_dim)`\n",
    "  - `self.w`: Weight matrix of shape `(in_dim, out_dim)`\n",
    "  -\t`self.b`: Bias matrix of shape `(1, out_dim)`\n",
    "-\tThe result is a matrix out of shape `(batch_size, out_dim)`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## **Backward Pass**\n",
    "- The backward pass computes gradients needed for updating the weights and biases. Given the upstream gradient `up_grad` (from the loss with respect to the output of this layer), we calculate:\n",
    "  - Gradient w.r.t. weights (`self.dw`):\n",
    "    $ \\frac{\\partial L}{\\partial W} = \\mathbf{inp}^T \\cdot \\text{up\\_grad} $\n",
    "  - Gradient w.r.t. biases (`self.db`):\n",
    "    $ \\frac{\\partial L}{\\partial b} = \\sum \\text{up\\_grad} \\text{ (summed across batch)} $\n",
    "  - Gradient to propagate to the previous layer (`down_grad`):\n",
    "    $ \\text{down\\_grad} = \\text{up\\_grad} \\cdot W^T $\n",
    "- This allows the gradient to flow backward to earlier layers.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Step Method**\n",
    "- Updates the weights and biases using the computed gradients and learning rate (`learning_rate`):\n",
    "    $$W = W - lr \\cdot \\frac{\\partial L}{\\partial W}$$\n",
    "    $$b = b - lr \\cdot \\frac{\\partial L}{\\partial b}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        # HE initialization:\n",
    "        self.w  = 0.1 * np.random.randn(in_dim, out_dim)\n",
    "        #self.w = np.random.randn(in_dim, out_dim) * np.sqrt(2. / in_dim)  # He initialization\n",
    "        self.b  = np.zeros((1, out_dim))\n",
    "        self.dw = np.zeros_like(self.w)\n",
    "        self.db = np.zeros_like(self.b) \n",
    "    \n",
    "    def forward(self, inp: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Perform the linear transformation: output = inp * W + b\"\"\"\n",
    "        self.inp = inp\n",
    "        self.out = np.dot(inp, self.w) + self.b\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, up_grad: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Backpropagate the gradients through this layer: \"\"\"\n",
    "        # dw = round L / round w \n",
    "        self.dw = np.dot(self.inp.T, up_grad)\n",
    "        # dw = round L / round b\n",
    "        self.db = np.sum(up_grad, axis=0, keepdims=True)\n",
    "\n",
    "        down_grad = np.dot(up_grad, self.w.T)\n",
    "        return down_grad\n",
    "    \n",
    "    def step(self, learning_rate: float) -> None:\n",
    "        self.w -= learning_rate * self.dw\n",
    "        self.b -= learning_rate * self.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def forward(self, inp: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"ReLU Activation function: f(x) = max(0, x)\"\"\"\n",
    "        self.inp = inp\n",
    "        self.out = np.maximum(0, inp)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, up_grad: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Backward pass for ReLU: derivative is 1 where input > 0, else 0.\"\"\"\n",
    "        down_grad = up_grad * (self.inp > 0)  # Efficient boolean indexing\n",
    "        return down_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "    def forward(self, inp: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Softmax activation: f(x) = exp(x) / sum(esp(x))\"\"\"\n",
    "        # subtract max for numerical stability:\n",
    "        exp_values = np.exp(inp - np.max(inp, axis=1, keepdims=True) )\n",
    "        self.out   = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, up_grad: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Backward pass for Softmax using the Jacobian matrix.\"\"\"\n",
    "        down_grad = np.empty_like(up_grad)\n",
    "        for i in range(up_grad.shape[0]):\n",
    "            single_output = self.out[i].reshape(-1, 1)\n",
    "            jacobian      = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "            down_grad[i]  = np.dot(jacobian, up_grad[i])\n",
    "        return down_grad\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why does softmax use the Jacobian as a derivative:\n",
    "A Jacobian is used when the output of a function depends on all inputs.\n",
    "Thanks for pointing that out — let's slow it down and **explain what it means for a function to be element-wise**, and why that matters for backpropagation.\n",
    "\n",
    "---\n",
    "\n",
    "What does *element-wise* mean?\n",
    "\n",
    "When we say a function is **element-wise**, we mean that:\n",
    "\n",
    "> **Each output value depends on exactly one input value**, and not on the others.\n",
    "\n",
    "In symbols:\n",
    "* Input: $x = [x_1, x_2, x_3]$\n",
    "* Output: $y = f(x) = [f(x_1), f(x_2), f(x_3)]$\n",
    "Each $y_i = f(x_i)$, completely **independent** of the other $x_j$\n",
    "---\n",
    "Example: ReLU is element-wise\n",
    "\n",
    "```python\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "```\n",
    "Input:\n",
    "\n",
    "```python\n",
    "x = [-2, 3, -1]\n",
    "```\n",
    "Output:\n",
    "\n",
    "```python\n",
    "relu(x) = [0, 3, 0]\n",
    "```\n",
    "\n",
    "* The output at position 0 (which is 0) comes **only** from the input at position 0 (which is -2).\n",
    "* It does **not** depend on `x[1]` or `x[2]`.\n",
    "\n",
    "So we can compute the derivative (gradient) for each position **individually**:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_i}{\\partial x_i} = \n",
    "\\begin{cases}\n",
    "1 & \\text{if } x_i > 0 \\\\\n",
    "0 & \\text{if } x_i \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "And this is why the backward pass is so simple:\n",
    "\n",
    "```python\n",
    "down_grad = up_grad * (self.inp > 0)\n",
    "```\n",
    "\n",
    "Just multiply the gradient at each index by either 1 or 0 — no interference between indices.\n",
    "\n",
    "---\n",
    "\n",
    "Softmax is **not** element-wise:\n",
    "$$\n",
    "\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\n",
    "$$\n",
    "That means each output $y_i$ is:\n",
    "* a fraction that includes **every** $z_j$ in the denominator.\n",
    "So the output $y_0$ depends on:\n",
    "* $z_0$, because of the numerator,\n",
    "* **and** all $z_j$ (including $z_1, z_2, ...$) because they’re in the denominator.\n",
    "Same goes for $y_1, y_2$, etc.\n",
    "\n",
    "Result:\n",
    "\n",
    "* Changing one input $z_j$ affects **all** outputs $y_i$\n",
    "* So we can't compute the derivative of $y_i$ w\\.r.t. $z_j$ independently\n",
    "* That’s why we need the **Jacobian matrix**, to keep track of **how every input affects every output**\n",
    "\n",
    "\n",
    "\n",
    "| Layer   | Formula                                   | Output depends on…    | Needs Jacobian? |\n",
    "| ------- | ----------------------------------------- | --------------------- | --------------- |\n",
    "| ReLU    | $f(x_i) = \\max(0, x_i)$                   | Only one input $x_i$  | ❌ No            |\n",
    "| Softmax | $f(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}}$ | All inputs $x_0..x_n$ | ✅ Yes           |\n",
    "\n",
    "---\n",
    "\n",
    "In backpropagation:\n",
    "\n",
    "* For **ReLU**, it's enough to use a simple mask.\n",
    "* For **Softmax**, you must account for all interactions — which is what the Jacobian matrix does.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstrac Loss Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self):\n",
    "        self.predicted = None\n",
    "        self.target    = None\n",
    "        self.loss      = None\n",
    "    \n",
    "    def __call__(self, prediction: np.ndarray, target: np.ndarray) -> float:\n",
    "        return self.forward(prediction, target)\n",
    "    \n",
    "    def forward(self, prediction:np.ndarray, target: np.ndarray) -> float:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def backward(self) -> np.ndarray:\n",
    "        raise NotImplementedError        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Entropy Loss\n",
    "\n",
    "Cross-entropy loss is typically used in classification tasks since it measures the dissimilarity between the true distribution (target) and the predicted probability distribution (prediction):\n",
    "\n",
    "$$L = - \\frac{1}{N} \\sum_{i} \\sum_{c} y_{ic} \\log(p_{ic})$$\n",
    "\n",
    "where $y_{ic}$ is the one-hot encoded true label (target), $p_{ic}$ is the predicted probability (output from Softmax) and $N$ is the batch size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(Loss):\n",
    "    def forward(self, prediction: np.ndarray, target: np.ndarray) -> float:\n",
    "        \"\"\"Cross-Entropy Loss for classification.\"\"\"\n",
    "        self.prediction = prediction\n",
    "        self.target = target\n",
    "        # Clip predictions to avoid log(0)\n",
    "        clipped_pred = np.clip(prediction, 1e-12, 1.0)\n",
    "        # Compute and return the loss\n",
    "        self.loss = -np.mean(np.sum(target * np.log(clipped_pred), axis=1))\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self) -> np.ndarray:\n",
    "        \"\"\"Gradient of Cross-Entropy Loss.\"\"\"\n",
    "        # Gradient wrt prediction (assuming softmax and one-hot targets)\n",
    "        grad = -self.target / self.prediction / self.target.shape[0]\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, layers: list[Layer], loss_func: Loss, learning_rate: float) -> None:\n",
    "        self.layers        = layers\n",
    "        self.loss_func     = loss_func\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def __call__(self, input: np.ndarray) -> np.ndarray:\n",
    "        return self.forward(input)\n",
    "    \n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" pass input through each layer sequentially \"\"\"\n",
    "        for layer in self.layers:\n",
    "            print(\"Iam in layer\", layer.shape)\n",
    "            input = layer.forward(input)\n",
    "        return input\n",
    "    \n",
    "    def loss(self, prediction: np.ndarray, target: np.ndarray) -> float:\n",
    "        \"\"\"Calculate Loss\"\"\"\n",
    "        return self.loss_func(prediction, target)\n",
    "    \n",
    "    def backward(self) -> None:\n",
    "        up_grad = self.loss_func.backward()\n",
    "        for layer in reversed(self.layers):\n",
    "            up_grad = layer.backward(up_grad)\n",
    "    \n",
    "    def update(self) -> None:\n",
    "        for layer in self.layers:\n",
    "            layer.step(self.learning_rate)\n",
    "    \n",
    "    def train(self, x_train: np.ndarray, y_train: np.ndarray, epochs: int, batch_size: int) -> np.ndarray:\n",
    "        losses = np.empty(epochs)\n",
    "        for epoch in (pbar := trange(epochs)):\n",
    "            running_loss = 0.0\n",
    "            for i in range(0, len(x_train), batch_size):\n",
    "                x_batch = x_train[i:i + batch_size]\n",
    "                y_batch = y_train[i:i + batch_size]\n",
    "\n",
    "                #Forward pass:\n",
    "                prediction = self.forward(x_batch)\n",
    "\n",
    "                #Compute loss:\n",
    "                running_loss += self.loss(prediction, y_batch) * batch_size\n",
    "\n",
    "                #Backward pass:\n",
    "                self.backward()\n",
    "\n",
    "                #Update the parameters:\n",
    "                self.update()\n",
    "            \n",
    "            #Normalize running loss by total number of samples:\n",
    "            running_loss /= len(x_train)\n",
    "            pbar.set_description(f\"Loss: {running_loss:.3f}\")\n",
    "            losses[epoch] = running_loss\n",
    "\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use MLP to solve a problem: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the Fashion-MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = fetch_openml(\"Fashion-MNIST\", parser='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n",
      "type of the fashion_mnist: <class 'sklearn.utils._bunch.Bunch'> \n",
      "\n",
      "keys of the fashion_mnist: dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])\n"
     ]
    }
   ],
   "source": [
    "print(type(fashion_mnist))\n",
    "print(f\"type of the fashion_mnist: {type(fashion_mnist)} \\n\")\n",
    "print(f\"keys of the fashion_mnist: {fashion_mnist.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(fashion_mnist['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset: (70000, 784)\n",
      "data of the fashion_mnist:    pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       1       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0      33   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
      "0        0  ...         0         0         0         0         0         0   \n",
      "1        0  ...       119       114       130        76         0         0   \n",
      "2       22  ...         0         0         1         0         0         0   \n",
      "3       96  ...         0         0         0         0         0         0   \n",
      "4        0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel781  pixel782  pixel783  pixel784  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"shape of the dataset: {fashion_mnist['data'].shape}\")\n",
    "print(f\"data of the fashion_mnist: {fashion_mnist['data'].head()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing explained:\n",
    "- fashion_mnist['data'].shape[0] = 70000 → number of images (indexes from 0 to 69999).\n",
    "- fashion_mnist['data'].shape[1] = 784 → number of pixels in each image (indexes from 0 to 783)\n",
    "\n",
    "#### So:\n",
    "- When you do fashion_mnist['data'][index] — you are selecting the entire image at that row index (a 1D array of 784 pixels).\n",
    "\n",
    "- When you do fashion_mnist['data'][index][pixel] — you are selecting a single pixel value from the image at index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel1      0\n",
      "pixel2      0\n",
      "pixel3      0\n",
      "pixel4      0\n",
      "pixel5      0\n",
      "           ..\n",
      "pixel780    0\n",
      "pixel781    0\n",
      "pixel782    0\n",
      "pixel783    0\n",
      "pixel784    0\n",
      "Name: 0, Length: 784, dtype: int64\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Access first row (image 0) in the DataFrame\n",
    "first_image_row = fashion_mnist['data'].iloc[0]  # iloc for positional indexing\n",
    "\n",
    "print(first_image_row)  # This is a pandas Series with pixel columns\n",
    "\n",
    "# Access pixel 0 value in this row:\n",
    "print(first_image_row.iloc[0])\n",
    "\n",
    "# Or simply chain:\n",
    "print(fashion_mnist['data'].iloc[0].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names of the fashion_mnist: ['pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7', 'pixel8', 'pixel9', 'pixel10', 'pixel11', 'pixel12', 'pixel13', 'pixel14', 'pixel15', 'pixel16', 'pixel17', 'pixel18', 'pixel19', 'pixel20', 'pixel21', 'pixel22', 'pixel23', 'pixel24', 'pixel25', 'pixel26', 'pixel27', 'pixel28', 'pixel29', 'pixel30', 'pixel31', 'pixel32', 'pixel33', 'pixel34', 'pixel35', 'pixel36', 'pixel37', 'pixel38', 'pixel39', 'pixel40', 'pixel41', 'pixel42', 'pixel43', 'pixel44', 'pixel45', 'pixel46', 'pixel47', 'pixel48', 'pixel49', 'pixel50', 'pixel51', 'pixel52', 'pixel53', 'pixel54', 'pixel55', 'pixel56', 'pixel57', 'pixel58', 'pixel59', 'pixel60', 'pixel61', 'pixel62', 'pixel63', 'pixel64', 'pixel65', 'pixel66', 'pixel67', 'pixel68', 'pixel69', 'pixel70', 'pixel71', 'pixel72', 'pixel73', 'pixel74', 'pixel75', 'pixel76', 'pixel77', 'pixel78', 'pixel79', 'pixel80', 'pixel81', 'pixel82', 'pixel83', 'pixel84', 'pixel85', 'pixel86', 'pixel87', 'pixel88', 'pixel89', 'pixel90', 'pixel91', 'pixel92', 'pixel93', 'pixel94', 'pixel95', 'pixel96', 'pixel97', 'pixel98', 'pixel99', 'pixel100', 'pixel101', 'pixel102', 'pixel103', 'pixel104', 'pixel105', 'pixel106', 'pixel107', 'pixel108', 'pixel109', 'pixel110', 'pixel111', 'pixel112', 'pixel113', 'pixel114', 'pixel115', 'pixel116', 'pixel117', 'pixel118', 'pixel119', 'pixel120', 'pixel121', 'pixel122', 'pixel123', 'pixel124', 'pixel125', 'pixel126', 'pixel127', 'pixel128', 'pixel129', 'pixel130', 'pixel131', 'pixel132', 'pixel133', 'pixel134', 'pixel135', 'pixel136', 'pixel137', 'pixel138', 'pixel139', 'pixel140', 'pixel141', 'pixel142', 'pixel143', 'pixel144', 'pixel145', 'pixel146', 'pixel147', 'pixel148', 'pixel149', 'pixel150', 'pixel151', 'pixel152', 'pixel153', 'pixel154', 'pixel155', 'pixel156', 'pixel157', 'pixel158', 'pixel159', 'pixel160', 'pixel161', 'pixel162', 'pixel163', 'pixel164', 'pixel165', 'pixel166', 'pixel167', 'pixel168', 'pixel169', 'pixel170', 'pixel171', 'pixel172', 'pixel173', 'pixel174', 'pixel175', 'pixel176', 'pixel177', 'pixel178', 'pixel179', 'pixel180', 'pixel181', 'pixel182', 'pixel183', 'pixel184', 'pixel185', 'pixel186', 'pixel187', 'pixel188', 'pixel189', 'pixel190', 'pixel191', 'pixel192', 'pixel193', 'pixel194', 'pixel195', 'pixel196', 'pixel197', 'pixel198', 'pixel199', 'pixel200', 'pixel201', 'pixel202', 'pixel203', 'pixel204', 'pixel205', 'pixel206', 'pixel207', 'pixel208', 'pixel209', 'pixel210', 'pixel211', 'pixel212', 'pixel213', 'pixel214', 'pixel215', 'pixel216', 'pixel217', 'pixel218', 'pixel219', 'pixel220', 'pixel221', 'pixel222', 'pixel223', 'pixel224', 'pixel225', 'pixel226', 'pixel227', 'pixel228', 'pixel229', 'pixel230', 'pixel231', 'pixel232', 'pixel233', 'pixel234', 'pixel235', 'pixel236', 'pixel237', 'pixel238', 'pixel239', 'pixel240', 'pixel241', 'pixel242', 'pixel243', 'pixel244', 'pixel245', 'pixel246', 'pixel247', 'pixel248', 'pixel249', 'pixel250', 'pixel251', 'pixel252', 'pixel253', 'pixel254', 'pixel255', 'pixel256', 'pixel257', 'pixel258', 'pixel259', 'pixel260', 'pixel261', 'pixel262', 'pixel263', 'pixel264', 'pixel265', 'pixel266', 'pixel267', 'pixel268', 'pixel269', 'pixel270', 'pixel271', 'pixel272', 'pixel273', 'pixel274', 'pixel275', 'pixel276', 'pixel277', 'pixel278', 'pixel279', 'pixel280', 'pixel281', 'pixel282', 'pixel283', 'pixel284', 'pixel285', 'pixel286', 'pixel287', 'pixel288', 'pixel289', 'pixel290', 'pixel291', 'pixel292', 'pixel293', 'pixel294', 'pixel295', 'pixel296', 'pixel297', 'pixel298', 'pixel299', 'pixel300', 'pixel301', 'pixel302', 'pixel303', 'pixel304', 'pixel305', 'pixel306', 'pixel307', 'pixel308', 'pixel309', 'pixel310', 'pixel311', 'pixel312', 'pixel313', 'pixel314', 'pixel315', 'pixel316', 'pixel317', 'pixel318', 'pixel319', 'pixel320', 'pixel321', 'pixel322', 'pixel323', 'pixel324', 'pixel325', 'pixel326', 'pixel327', 'pixel328', 'pixel329', 'pixel330', 'pixel331', 'pixel332', 'pixel333', 'pixel334', 'pixel335', 'pixel336', 'pixel337', 'pixel338', 'pixel339', 'pixel340', 'pixel341', 'pixel342', 'pixel343', 'pixel344', 'pixel345', 'pixel346', 'pixel347', 'pixel348', 'pixel349', 'pixel350', 'pixel351', 'pixel352', 'pixel353', 'pixel354', 'pixel355', 'pixel356', 'pixel357', 'pixel358', 'pixel359', 'pixel360', 'pixel361', 'pixel362', 'pixel363', 'pixel364', 'pixel365', 'pixel366', 'pixel367', 'pixel368', 'pixel369', 'pixel370', 'pixel371', 'pixel372', 'pixel373', 'pixel374', 'pixel375', 'pixel376', 'pixel377', 'pixel378', 'pixel379', 'pixel380', 'pixel381', 'pixel382', 'pixel383', 'pixel384', 'pixel385', 'pixel386', 'pixel387', 'pixel388', 'pixel389', 'pixel390', 'pixel391', 'pixel392', 'pixel393', 'pixel394', 'pixel395', 'pixel396', 'pixel397', 'pixel398', 'pixel399', 'pixel400', 'pixel401', 'pixel402', 'pixel403', 'pixel404', 'pixel405', 'pixel406', 'pixel407', 'pixel408', 'pixel409', 'pixel410', 'pixel411', 'pixel412', 'pixel413', 'pixel414', 'pixel415', 'pixel416', 'pixel417', 'pixel418', 'pixel419', 'pixel420', 'pixel421', 'pixel422', 'pixel423', 'pixel424', 'pixel425', 'pixel426', 'pixel427', 'pixel428', 'pixel429', 'pixel430', 'pixel431', 'pixel432', 'pixel433', 'pixel434', 'pixel435', 'pixel436', 'pixel437', 'pixel438', 'pixel439', 'pixel440', 'pixel441', 'pixel442', 'pixel443', 'pixel444', 'pixel445', 'pixel446', 'pixel447', 'pixel448', 'pixel449', 'pixel450', 'pixel451', 'pixel452', 'pixel453', 'pixel454', 'pixel455', 'pixel456', 'pixel457', 'pixel458', 'pixel459', 'pixel460', 'pixel461', 'pixel462', 'pixel463', 'pixel464', 'pixel465', 'pixel466', 'pixel467', 'pixel468', 'pixel469', 'pixel470', 'pixel471', 'pixel472', 'pixel473', 'pixel474', 'pixel475', 'pixel476', 'pixel477', 'pixel478', 'pixel479', 'pixel480', 'pixel481', 'pixel482', 'pixel483', 'pixel484', 'pixel485', 'pixel486', 'pixel487', 'pixel488', 'pixel489', 'pixel490', 'pixel491', 'pixel492', 'pixel493', 'pixel494', 'pixel495', 'pixel496', 'pixel497', 'pixel498', 'pixel499', 'pixel500', 'pixel501', 'pixel502', 'pixel503', 'pixel504', 'pixel505', 'pixel506', 'pixel507', 'pixel508', 'pixel509', 'pixel510', 'pixel511', 'pixel512', 'pixel513', 'pixel514', 'pixel515', 'pixel516', 'pixel517', 'pixel518', 'pixel519', 'pixel520', 'pixel521', 'pixel522', 'pixel523', 'pixel524', 'pixel525', 'pixel526', 'pixel527', 'pixel528', 'pixel529', 'pixel530', 'pixel531', 'pixel532', 'pixel533', 'pixel534', 'pixel535', 'pixel536', 'pixel537', 'pixel538', 'pixel539', 'pixel540', 'pixel541', 'pixel542', 'pixel543', 'pixel544', 'pixel545', 'pixel546', 'pixel547', 'pixel548', 'pixel549', 'pixel550', 'pixel551', 'pixel552', 'pixel553', 'pixel554', 'pixel555', 'pixel556', 'pixel557', 'pixel558', 'pixel559', 'pixel560', 'pixel561', 'pixel562', 'pixel563', 'pixel564', 'pixel565', 'pixel566', 'pixel567', 'pixel568', 'pixel569', 'pixel570', 'pixel571', 'pixel572', 'pixel573', 'pixel574', 'pixel575', 'pixel576', 'pixel577', 'pixel578', 'pixel579', 'pixel580', 'pixel581', 'pixel582', 'pixel583', 'pixel584', 'pixel585', 'pixel586', 'pixel587', 'pixel588', 'pixel589', 'pixel590', 'pixel591', 'pixel592', 'pixel593', 'pixel594', 'pixel595', 'pixel596', 'pixel597', 'pixel598', 'pixel599', 'pixel600', 'pixel601', 'pixel602', 'pixel603', 'pixel604', 'pixel605', 'pixel606', 'pixel607', 'pixel608', 'pixel609', 'pixel610', 'pixel611', 'pixel612', 'pixel613', 'pixel614', 'pixel615', 'pixel616', 'pixel617', 'pixel618', 'pixel619', 'pixel620', 'pixel621', 'pixel622', 'pixel623', 'pixel624', 'pixel625', 'pixel626', 'pixel627', 'pixel628', 'pixel629', 'pixel630', 'pixel631', 'pixel632', 'pixel633', 'pixel634', 'pixel635', 'pixel636', 'pixel637', 'pixel638', 'pixel639', 'pixel640', 'pixel641', 'pixel642', 'pixel643', 'pixel644', 'pixel645', 'pixel646', 'pixel647', 'pixel648', 'pixel649', 'pixel650', 'pixel651', 'pixel652', 'pixel653', 'pixel654', 'pixel655', 'pixel656', 'pixel657', 'pixel658', 'pixel659', 'pixel660', 'pixel661', 'pixel662', 'pixel663', 'pixel664', 'pixel665', 'pixel666', 'pixel667', 'pixel668', 'pixel669', 'pixel670', 'pixel671', 'pixel672', 'pixel673', 'pixel674', 'pixel675', 'pixel676', 'pixel677', 'pixel678', 'pixel679', 'pixel680', 'pixel681', 'pixel682', 'pixel683', 'pixel684', 'pixel685', 'pixel686', 'pixel687', 'pixel688', 'pixel689', 'pixel690', 'pixel691', 'pixel692', 'pixel693', 'pixel694', 'pixel695', 'pixel696', 'pixel697', 'pixel698', 'pixel699', 'pixel700', 'pixel701', 'pixel702', 'pixel703', 'pixel704', 'pixel705', 'pixel706', 'pixel707', 'pixel708', 'pixel709', 'pixel710', 'pixel711', 'pixel712', 'pixel713', 'pixel714', 'pixel715', 'pixel716', 'pixel717', 'pixel718', 'pixel719', 'pixel720', 'pixel721', 'pixel722', 'pixel723', 'pixel724', 'pixel725', 'pixel726', 'pixel727', 'pixel728', 'pixel729', 'pixel730', 'pixel731', 'pixel732', 'pixel733', 'pixel734', 'pixel735', 'pixel736', 'pixel737', 'pixel738', 'pixel739', 'pixel740', 'pixel741', 'pixel742', 'pixel743', 'pixel744', 'pixel745', 'pixel746', 'pixel747', 'pixel748', 'pixel749', 'pixel750', 'pixel751', 'pixel752', 'pixel753', 'pixel754', 'pixel755', 'pixel756', 'pixel757', 'pixel758', 'pixel759', 'pixel760', 'pixel761', 'pixel762', 'pixel763', 'pixel764', 'pixel765', 'pixel766', 'pixel767', 'pixel768', 'pixel769', 'pixel770', 'pixel771', 'pixel772', 'pixel773', 'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780', 'pixel781', 'pixel782', 'pixel783', 'pixel784']\n",
      "target names of the fashion_mnist: ['class']\n"
     ]
    }
   ],
   "source": [
    "print(f\"feature names of the fashion_mnist: {fashion_mnist['feature_names']}\")\n",
    "print(f\"target names of the fashion_mnist: {fashion_mnist['target_names']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n",
      "i: class\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#The dataset’s target_names list only contains the name of the target column, which is \"class\".\n",
    "target_names = fashion_mnist['target_names']\n",
    "\n",
    "print(type(target_names))\n",
    "\n",
    "print(len(target_names))\n",
    "\n",
    "for i in target_names:\n",
    "    print(f\"i: {i}\")\n",
    "    print(type(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLot the MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image pixel array shape: (784,)\n",
      "First pixel value of first image: 0\n",
      "Label number: 9\n",
      "Label name: Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppose fashion_mnist is loaded as a dictionary with pandas DataFrames/Series\n",
    "# Example class names mapping:\n",
    "class_names = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}\n",
    "\n",
    "index = 0  # Index of the image to examine\n",
    "\n",
    "# Access image pixels as pandas Series and convert to numpy array\n",
    "image_pixels = fashion_mnist['data'].iloc[index].values\n",
    "\n",
    "# Access first pixel value\n",
    "first_pixel_value = image_pixels[0]\n",
    "\n",
    "# Access label\n",
    "label = fashion_mnist['target'].iloc[index]\n",
    "\n",
    "print(f\"First image pixel array shape: {image_pixels.shape}\")  # Should be (784,)\n",
    "print(f\"First pixel value of first image: {first_pixel_value}\")\n",
    "print(f\"Label number: {label}\")\n",
    "print(f\"Label name: {class_names[int(label)]}\")\n",
    "\n",
    "# Reshape to 28x28 for visualization\n",
    "image_2d = image_pixels.reshape(28, 28)\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(image_2d, cmap='gray')\n",
    "plt.title(f\"Class: {class_names[int(label)]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary of the **Fashion MNIST dataset** :\n",
    "\n",
    "**Fashion MNIST Dataset – Full Summary**\n",
    "\n",
    "* **What it is**:\n",
    "  A benchmark dataset for machine learning, used to train and evaluate image classification models on clothing item recognition.\n",
    "\n",
    "* **Total Samples**: **70,000 grayscale images**\n",
    "\n",
    "  * **60,000 training samples**\n",
    "  * **10,000 test samples**\n",
    "\n",
    "* **Image Details**:\n",
    "\n",
    "  * Each image is **28 × 28 pixels** = **784 pixels total**\n",
    "  * Stored as a **flattened 1D array of 784 values**\n",
    "  * Each pixel is a **grayscale intensity**: value between **0 (black)** and **255 (white)**\n",
    "\n",
    "* **Features**:\n",
    "\n",
    "  * Named `pixel1`, `pixel2`, ..., `pixel784`\n",
    "  * Represent the brightness level of each pixel\n",
    "  * No color (only black and white shades)\n",
    "\n",
    "* **Target Labels**:\n",
    "  One label per image, from **0 to 9**, representing the clothing type\n",
    "\n",
    "| Label | Clothing Item |\n",
    "| ----- | ------------- |\n",
    "| 0     | T-shirt/top   |\n",
    "| 1     | Trouser       |\n",
    "| 2     | Pullover      |\n",
    "| 3     | Dress         |\n",
    "| 4     | Coat          |\n",
    "| 5     | Sandal        |\n",
    "| 6     | Shirt         |\n",
    "| 7     | Sneaker       |\n",
    "| 8     | Bag           |\n",
    "| 9     | Ankle boot    |\n",
    "\n",
    "* **Data Format**:\n",
    "  * Usually loaded as a **dictionary-like object**\n",
    "  * Keys: `'data'`, `'target'`, `'feature_names'`, `'target_names'`, `'DESCR'`, etc.\n",
    "  * `data` contains pixel values\n",
    "  * `target` contains class labels\n",
    "  * `frame` (if available) is a `pandas.DataFrame` with both\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Fashion-MNIST dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min-Max normalization:\n",
    "Certainly! Here's the general **min-max normalization formula**, which scales a value $x$ from its original range $[x_{\\text{min}}, x_{\\text{max}}]$ to a new range $[a, b]$:\n",
    "\n",
    "$$\n",
    "x_{\\text{norm}} = a + \\left( \\frac{x - x_{\\text{min}}}{x_{\\text{max}} - x_{\\text{min}}} \\right) \\times (b - a)\n",
    "$$\n",
    "\n",
    "#### Special Case: Normalize to $[-1, 1]$\n",
    "\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{2(x - x_{\\text{min}})}{x_{\\text{max}} - x_{\\text{min}}} - 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min-Max Normalization: From $[0, 255]$ to $[-1, 1]$\n",
    "\n",
    "To normalize a value $x \\in [0, 255]$ into the range $[-1, 1]$, you can use the **min-max normalization** formula:\n",
    "\n",
    "Sure! To normalize a value $x \\in [0, 255]$ into the range $[-1, 1]$, you use this **min-max normalization** formula:\n",
    "\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{2x}{255} - 1\n",
    "$$\n",
    "\n",
    "##### Explanation:\n",
    "\n",
    "This follows directly from:\n",
    "\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{2(x - x_{\\text{min}})}{x_{\\text{max}} - x_{\\text{min}}} - 1\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $x_{\\text{min}} = 0$\n",
    "* $x_{\\text{max}} = 255$\n",
    "\n",
    "Plug in:\n",
    "\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{2(x - 0)}{255 - 0} - 1 = \\frac{2x}{255} - 1\n",
    "$$\n",
    "\n",
    "This maps:\n",
    "\n",
    "* $x = 0 \\rightarrow -1$\n",
    "* $x = 127.5 \\rightarrow 0$\n",
    "* $x = 255 \\rightarrow +1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filter_classes):\n",
    "    fashion_mnist = fetch_openml(\"Fashion-MNIST\", parser='auto')\n",
    "    x, y = fashion_mnist['data'], fashion_mnist['target'].astype(int)\n",
    "    # Remove classes\n",
    "    filtered_indices = np.isin(y, filter_classes)\n",
    "    x, y = x[filtered_indices].to_numpy(), y[filtered_indices]\n",
    "    # Normalize the pixels to be in [-1, +1] range\n",
    "    x = ((x / 255.) - .5) * 2\n",
    "    removed_class_count = 0\n",
    "    for i in range(10):  # Fix the labels\n",
    "        if i in filter_classes and removed_class_count != 0:\n",
    "            y[y == i] = i - removed_class_count\n",
    "        elif i not in filter_classes:\n",
    "            removed_class_count += 1\n",
    "    # Do the train-test split\n",
    "    return train_test_split(x, y, test_size=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Fashion-MNIST Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoder(y, num_labels):\n",
    "    one_hot = np.zeros(shape=(y.size, num_labels), dtype=int)\n",
    "    one_hot[np.arange(y.size), y] = 1\n",
    "    return one_hot\n",
    "\n",
    "class_names = {0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover',\n",
    "               3: 'Dress', 4: 'Coat', 5:  'Sandal', 6: 'Shirt',\n",
    "               7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'}\n",
    "\n",
    "kept_classes = [0, 1, 7] #t_shirt, trouser, sneaker\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_data(kept_classes)\n",
    "\n",
    "# One-hot encode the target labels of the training set\n",
    "y_train = onehot_encoder(y_train, num_labels=len(kept_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11488/3370435463.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mplot_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11488/1069868629.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[1;31m#Forward pass:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[1;31m#Compute loss:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11488/1069868629.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;34m\"\"\" pass input through each layer sequentially \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Iam in layer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "def plot_training(losses):\n",
    "    # Plot the loss\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "layers = [Linear(784, 50),\n",
    "          ReLU(),\n",
    "          Linear(50, 50),\n",
    "          ReLU(),\n",
    "          Linear(50, len(kept_classes)),\n",
    "          Softmax()]\n",
    "\n",
    "model = MLP(layers, CrossEntropy(), learning_rate=0.001) \n",
    "\n",
    "# Train the model\n",
    "losses = model.train(x_train, y_train, epochs=30, batch_size=64)\n",
    "\n",
    "plot_training(losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How forward layer works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "Linear output z = [[ 6.  6.]\n",
      " [15. 15.]]\n",
      "After layer forward, out = [[ 6.  6.]\n",
      " [15. 15.]]\n",
      "[[ 6.  6.]\n",
      " [15. 15.]]\n",
      "ReLU output a = [[ 6.  6.]\n",
      " [15. 15.]]\n",
      "After layer forward, out = [[ 6.  6.]\n",
      " [15. 15.]]\n",
      "Final output = [[ 6.  6.]\n",
      " [15. 15.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Tiny example ---\n",
    "# Input (batch of 2 samples, each with 3 features)\n",
    "X = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "\n",
    "# Linear layer\n",
    "class Linear:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.W = np.ones((in_features, out_features))  # just ones for simplicity\n",
    "        self.b = np.zeros((1, out_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = x @ self.W + self.b\n",
    "        print(\"Linear output z =\", z)\n",
    "        return z\n",
    "\n",
    "# ReLU layer\n",
    "class ReLU:\n",
    "    def forward(self, x):\n",
    "        a = np.maximum(0, x)\n",
    "        print(\"ReLU output a =\", a)\n",
    "        return a\n",
    "\n",
    "# --- Build network ---\n",
    "layers = [Linear(3, 2), ReLU()]\n",
    "\n",
    "# --- Forward pass ---\n",
    "out = X\n",
    "for layer in layers:\n",
    "    print(out)\n",
    "    out = layer.forward(out)\n",
    "    print(\"After layer forward, out =\", out)\n",
    "\n",
    "print(\"Final output =\", out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah! I see exactly what’s confusing you. 😄 Let’s carefully break it down. This is a **common point of confusion when you first do forward passes in neural networks**.\n",
    "\n",
    "Here’s the key snippet in your code:\n",
    "\n",
    "```python\n",
    "out = X\n",
    "for layer in layers:\n",
    "    out = layer.forward(out)\n",
    "```\n",
    "\n",
    "### Step by step:\n",
    "\n",
    "1. **Initialization:**\n",
    "\n",
    "   ```python\n",
    "   out = X\n",
    "   ```\n",
    "\n",
    "   * `out` now **points to the input** `X`:\n",
    "\n",
    "     ```\n",
    "     [[1, 2, 3],\n",
    "      [4, 5, 6]]\n",
    "     ```\n",
    "\n",
    "2. **First iteration: `Linear` layer**\n",
    "\n",
    "   ```python\n",
    "   out = layer.forward(out)\n",
    "   ```\n",
    "\n",
    "   * The forward method of `Linear` does:\n",
    "\n",
    "     ```python\n",
    "     z = x @ self.W + self.b\n",
    "     ```\n",
    "\n",
    "     * `x @ self.W` is matrix multiplication (`@` is the dot product operator for NumPy).\n",
    "     * `self.W` is all ones: `[[1,1],[1,1],[1,1]]` for `in_features=3, out_features=2`.\n",
    "     * Compute `z`:\n",
    "\n",
    "       ```\n",
    "       z[0] = [1+2+3, 1+2+3] = [6, 6]\n",
    "       z[1] = [4+5+6, 4+5+6] = [15, 15]\n",
    "       ```\n",
    "     * So Linear output:\n",
    "\n",
    "       ```\n",
    "       [[6, 6],\n",
    "        [15, 15]]\n",
    "       ```\n",
    "   * `out` is **reassigned** to this Linear output. ✅\n",
    "\n",
    "3. **Second iteration: `ReLU` layer**\n",
    "\n",
    "   ```python\n",
    "   out = layer.forward(out)\n",
    "   ```\n",
    "\n",
    "   * Now `out` **is the Linear output** `[[6,6],[15,15]]`.\n",
    "   * ReLU does:\n",
    "\n",
    "     ```python\n",
    "     a = np.maximum(0, x)\n",
    "     ```\n",
    "\n",
    "     * ReLU keeps positive numbers as-is (and zeros out negatives).\n",
    "     * Here, all numbers are positive, so output is unchanged:\n",
    "\n",
    "       ```\n",
    "       [[6, 6],\n",
    "        [15, 15]]\n",
    "       ```\n",
    "   * `out` is reassigned to this ReLU output.\n",
    "\n",
    "4. **End result:**\n",
    "\n",
    "   ```python\n",
    "   print(\"Final output =\", out)\n",
    "   ```\n",
    "\n",
    "   * Shows the ReLU output:\n",
    "\n",
    "     ```\n",
    "     [[6, 6],\n",
    "      [15, 15]]\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### Why `out` is updated:\n",
    "\n",
    "* Each time we do `out = layer.forward(out)`, the variable `out` **gets replaced** with the layer’s output.\n",
    "* This is exactly how data flows through a network: the output of one layer becomes the input to the next.\n",
    "\n",
    "Think of it like passing a baton in a relay race: each layer modifies it, and then passes it to the next.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can **draw a little diagram showing the flow from `X → Linear → ReLU → out`** so it becomes crystal clear. It usually helps a lot.\n",
    "\n",
    "Do you want me to do that?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A got 5\n",
      "After layer: 6\n",
      "B got 6\n",
      "After layer: 12\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def forward(self, x):\n",
    "        print(\"A got\", x)\n",
    "        return x + 1\n",
    "\n",
    "class B:\n",
    "    def forward(self, x):\n",
    "        print(\"B got\", x)\n",
    "        return x * 2\n",
    "\n",
    "layers = [A(), B()]\n",
    "\n",
    "x = 5\n",
    "for layer in layers:\n",
    "    x = layer.forward(x)\n",
    "    print(\"After layer:\", x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
